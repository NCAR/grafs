from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression
from sklearn.pipeline import Pipeline
from sklearn.feature_selection import SelectKBest, f_regression
anova_filter = SelectKBest(f_regression, k=10)
config = dict(
    data_format="hdf",
    #data_format="csv",
    #data_path="/d2/dgagne/merged_data_multimodel/",
    #expression="nam_def_fcst.*.00.*",
    data_path="/d2/dgagne/full_grid_data/",
    expression="namdef_fcst.20150621.00*",
    #query=["av_dswrf_sfc_f < 30000", "valid_hour_pst >= 5", "valid_hour_pst < 22", "forecast_hour <= 36"],
    input_columns=["valid_hour_pst","forecast_hour","day_of_year","sine_doy",
                   "T_f","T_f_mean","T_f_max","T_f_min","T_f_correlate","T_f_gradient",
                   "av_dswrf_sfc_f","av_dswrf_sfc_f_mean","av_dswrf_sfc_f_max","av_dswrf_sfc_f_min",
                   "av_dswrf_sfc_f_correlate","av_dswrf_sfc_f_gradient"],
    output_column="av_dswrf_sfc",
    model_names= ["Random Forest", "Linear Regression", "Gradient Boosting"],
    model_objects = [RandomForestRegressor(n_estimators=100, max_depth=15, max_features='sqrt', n_jobs=10),
                    Pipeline([('anova', anova_filter),('lr', LinearRegression())]),
                    GradientBoostingRegressor(n_estimators=100, loss='lad', learning_rate=0.05,
                                              max_leaf_nodes=100000, max_features='auto', verbose=2)],
    n_folds=5,
    pred_columns=["valid_date", "run_date", "day_of_year", "station", "lon", "lat", "row", "col",
                  "forecast_hour", "valid_hour_pst", "valid_hour_utc", "av_dswrf_sfc_f", "av_dswrf_sfc"],
    split_day=166,
    site_pred_file="/d2/dgagne/site_predictions/site_predictions_nam.csv",
    ml_model_path="/d2/dgagne/ml_models_multimodel/nam_00/",
    pred_path="/d2/dgagne/ml_predictions/",
    pred_format="hdf",
)
